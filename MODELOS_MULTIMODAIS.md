# 🎯 Guia Rápido: Modelos Multimodais no AION

## O que são Modelos Multimodais?

Modelos multimodais combinam **visão** e **texto** para entender melhor o contexto:

- 👁️ **VÊ** screenshots da tela
- 📝 **LÊ** textos e elementos de UI
- 🎯 **DECIDE** ações baseadas no que vê

## 🚀 Modelos Recomendados

### Para dispositivos com 4-6GB RAM:
**LLaMA 3.2 Vision 1B** (0.9 GB) ⚡
- Mais rápido
- Menor consumo de RAM
- Ideal para tarefas simples

### Para dispositivos com 6-8GB RAM:
**MiniCPM-V 2B** (1.4 GB) 🔥
- Excelente custo-benefício
- Ótimo para automação de UI
- Equilíbrio perfeito

**Gemma 2 2B Vision** (1.6 GB) 🌟
- Do Google
- Bom multilíngue
- Eficiente e rápido

### Para dispositivos com 8GB+ RAM:
**LLaMA 3.2 Vision 3B** (1.9 GB) 💎
- Mais preciso
- Suporta alta resolução
- Recomendado para tarefas complexas

**Phi-3 Vision** (2.8 GB) 💎
- Microsoft
- Excelente OCR
- Raciocínio avançado

### Para dispositivos com 12GB+ RAM:
**LLaVA 1.6 Mistral 7B** (4.3 GB) 🏆
- Máxima precisão
- Melhor para UIs complexas
- Mais lento mas muito preciso

## 📊 Comparação Rápida

| Modelo | Tamanho | Velocidade | Precisão | RAM Mínima |
|--------|---------|------------|----------|------------|
| LLaMA 3.2 1B | 0.9 GB | ⚡⚡⚡⚡⚡ | ⭐⭐⭐⭐ | 4 GB |
| MiniCPM-V 2B | 1.4 GB | ⚡⚡⚡⚡ | ⭐⭐⭐⭐⭐ | 6 GB |
| Gemma 2 2B | 1.6 GB | ⚡⚡⚡⚡ | ⭐⭐⭐⭐ | 6 GB |
| LLaMA 3.2 3B | 1.9 GB | ⚡⚡⚡⚡ | ⭐⭐⭐⭐⭐ | 8 GB |
| Phi-3 Vision | 2.8 GB | ⚡⚡⚡ | ⭐⭐⭐⭐⭐ | 8 GB |
| LLaVA 1.6 7B | 4.3 GB | ⚡⚡ | ⭐⭐⭐⭐⭐ | 12 GB |

## 🎮 Como Usar

1. **Baixe o modelo** na aba "Modelos"
2. **Selecione** o modelo desejado
3. **Configure** o serviço de acessibilidade
4. **Digite uma tarefa** e deixe a IA ver e agir!

## 💡 Dicas

- Modelos menores são mais rápidos ⚡
- Modelos maiores são mais precisos 🎯
- Escolha baseado na RAM do seu dispositivo 📱
- Teste diferentes modelos para achar o ideal! 🧪

## 🔗 Mais Informações

Veja **MULTIMODAL_MODELS_INFO.md** para documentação completa.

---
**AION - IA Multimodal 100% Local** 🚀
